# NLP-Lec 2 数据资源

![image-20260116100954512](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116100954512.png)

## 2.1 数据资源概述

数据资源按机器学习方法分为：

- 概率统计时期
- 深度学习时期

**第一代：**百万词级，以语言研究为导向，如：Brown语料库、LLC语料库。

**第二代：**千万次级，词典编撰，以应用为导向，如：COBUILD语料库、Longman语料库。

**第三代：**上亿词级，标准编码体系，深度标注，多语种，如：ACL/DCI语料库、UPenn树库、LDC等。

**第四代：**互联网信息作为语料库。

## 2.2 统计时代语料资源

### 2.2.1 语料库

#### 语料库基本概念

存放语言材料等仓库，现代的语料库是指**存放在计算机里的原始语料文本**或**经过加工后带有语言学信息标注的语料文本**。

通过语言的真实材料为基础来呈现语言知识，反映语言单位的用法和意义，基本以知识的原始形态表现。

##### 语料库三大特征

- 存放在实际使用中**<u>真实</u>**出现过的语言材料
- **<u>以计算机为载体</u>**承载语言知识的基础资源
- 经过**<u>分析、处理和加工</u>**才能成为有用资源

##### 语料库的作用

- 支持**<u>语言学</u>**研究和语言教学研究
- 支持**<u>NLP系统</u>**的开发

#### 语料库的类型及相关术语

- **按内容构成和目的划分（四种类型）**
  - **异质的 (heterogeneous) ：**最简单的语料收集方法，没有事先规定和选材原则
  - **同质的（homogeneous）：**与“异质”正好相反，比如美国的 TIPSTER 项目只收集军事方面的文本
  - **系统的（systematic）：**充分考虑语料动态和静态问题、代表性和平衡问题以及语料库规模等问题
  - **专用的（specialized）：**如北美的人文科学语料库
- **按语言种类划分**
  - **单语**
  - **双语/多语：**如平行语料库（篇章对齐/句子对齐/结构对齐）
- **按是否加工处理过（标注）划分**
  - **生语料库：**未经加工的，没有任何切分、标注标记的原始语料库
  - **熟语料库：**经过加工，带有切分、标注标记的语料库，如具有词性标注、句法结构信息标注、语义信息标注
- **共时语料库与历时语料库**
  - **共时语料库：**是为了对语言进行共时（同一时段）研究而建立的语料库。
  - **历时语料库：**是为了对语言进行历时研究而建立的语料库

#### 典型的语料库资源：

- **布朗语料库（Brown Corpus）：**世界上第一个根据**系统性**原则采集样本的标准语料库，100万词规模
- **LLC口语语料库（London-Lund Corpus of Spoken English）**
- **朗文语料库（Longman Corpus）**

#### 语料库示例：

- **汉语词性标注**

![image-20260116104426894](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116104426894.png)

- **汉语词性及句法标注**

![image-20260116104441221](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116104441221.png)

- **语义角色标注**

![image-20260116104454668](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116104454668.png)

### 2.2.2 知识库

**语言知识库：**从大量实例语料中**<u>提炼</u>、<u>抽象</u>、<u>概括</u>**出来的系统的语言知识，如电子词典、句法规则库、词法分析规则库。

#### 典型的知识库

- **WordNet**
- **知识图谱**
- **常识知识库**

## 2.3 深度学习时代数据资源

### 2.3.1 任务数据资源

#### 任务数据

在**神经网络方法（第二范式）时期**，各类语言处理任务主要依靠**构建专门的任务神经网络模型**，并通过**有监督学习**对模型进行训练已完成对应任务。在这一阶段，所需的数据资源主要用于训练任务模型，因此使用的**数据集主要是针对具体任务进行标注的任务数据集**。但由于任务参数知识有限，在需要世界知识的任务上往往表现不佳，因此在第二范式时期常常会引入**知识图谱、常识图谱**等外部资源。

![image-20260116105645389](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116105645389.png)

- **文本分类任务数据集**

  - 20 Newsgroups

  - AG News

- **情感分析任务数据集**

  - 亚马逊评论数据集（Amazon Review Data）
  - 斯坦福情绪树库（Stanford Sentiment Treebank）

- **机器翻译任务数据集**

  - 开放字幕数据集（OpenSubtitles Corpus）
  - 联合国平行语料库（United Nations Parallel Corpus）

- **文本摘要任务数据集**

  - CNN每日邮报数据集（CNN DailyMail Dataset）
  - Reddit TIFU数据集

- **机器阅读理解任务数据集**

  - 斯坦福问答数据集
  - DuReader

- **问答任务数据集**

  - 维基问答语料库
  - Hotpot问答数据集

### 2.3.2 预训练数据资源

#### 预训练数据

在**预训练语言模型+精调（第三范式）时期**，模型训练采用“预训练+精调”的模式，即有预训练语言模型参数和下游任务参数共同构成。在这一阶段，需要**大量的预训练数据**对预训练模型进行训练，同时需要**少量的标注任务数据**对模型的任务参数进行微调。其中，所需的任务标注数据集可复用第二范式的任务数据。（*注：第四范式所用数据与第三范式基本相同，区别是第四范式微调不是调任务模型参数，而是微调预训练语言模型*）

![image-20260116110752954](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116110752954.png)

- **网页数据**
- **书籍**
- **学术资料**
- **维基百科**
- **代码**
- **混合型数据集**

### 2.3.3 预训练微调数据集

#### 预训练微调数据

在**大语言模型（第五范式）时期**，大模型训练采用“**预训练+后训练（微调）**”模式，即先通过预训练方式对大语言模型进行预训练，然后采用微调的方式让模型给出符合人类认知的输出，其中微调阶段又分为**指令微调**和**对齐微调**，指令微调主要让模型按人类的特定习惯给出输出，对齐微调主要是让模型输出的内容符合人类价值观和偏好。

![image-20260116111453020](/Users/fangyiqin/Library/Application Support/typora-user-images/image-20260116111453020.png)

- **微调指令数据集：**该类数据集是有标注数据集，主要对大语言模型进行符合人类习惯输出的微调训练，一般有人工标注数据集和用模型合成方法生成的数据集
- **人类对齐数据集：**将大语言模型与人类价值观和偏好对齐，现有对齐目标主要有：有用性、诚实性、无害性